{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Save this file as studentid1_studentid2_lab#.ipynb**\n",
    "(Your student-id is the number shown on your student card.)\n",
    "\n",
    "E.g. if you work with 3 people, the notebook should be named:\n",
    "12301230_3434343_1238938934_lab1.ipynb.\n",
    "\n",
    "**This will be parsed by a regexp, so please double check your filename.**\n",
    "\n",
    "Before you turn this problem in, please make sure everything runs correctly. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "**Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your names and email adresses below.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NAME = \"tk\"\n",
    "NAME2 = \"\"\n",
    "NAME3 = \"\"\n",
    "EMAIL = \"\"\n",
    "EMAIL2 = \"\"\n",
    "EMAIL3 = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c39ec76a03b2143870009fb35729e8e0",
     "grade": false,
     "grade_id": "cell-8d856208da5d0763",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Lab 2: Classification\n",
    "\n",
    "### Machine Learning 1, September 2017\n",
    "\n",
    "Notes on implementation:\n",
    "\n",
    "* You should write your code and answers in this IPython Notebook: http://ipython.org/notebook.html. If you have problems, please contact your teaching assistant.\n",
    "* Please write your answers right below the questions.\n",
    "* Among the first lines of your notebook should be \"%pylab inline\". This imports all required modules, and your plots will appear inline.\n",
    "* Use the provided test cells to check if your answers are correct\n",
    "* **Make sure your output and plots are correct before handing in your assignment with Kernel -> Restart & Run All**\n",
    "\n",
    "$\\newcommand{\\bx}{\\mathbf{x}}$\n",
    "$\\newcommand{\\bw}{\\mathbf{w}}$\n",
    "$\\newcommand{\\bt}{\\mathbf{t}}$\n",
    "$\\newcommand{\\by}{\\mathbf{y}}$\n",
    "$\\newcommand{\\bm}{\\mathbf{m}}$\n",
    "$\\newcommand{\\bb}{\\mathbf{b}}$\n",
    "$\\newcommand{\\bS}{\\mathbf{S}}$\n",
    "$\\newcommand{\\ba}{\\mathbf{a}}$\n",
    "$\\newcommand{\\bz}{\\mathbf{z}}$\n",
    "$\\newcommand{\\bv}{\\mathbf{v}}$\n",
    "$\\newcommand{\\bq}{\\mathbf{q}}$\n",
    "$\\newcommand{\\bp}{\\mathbf{p}}$\n",
    "$\\newcommand{\\bh}{\\mathbf{h}}$\n",
    "$\\newcommand{\\bI}{\\mathbf{I}}$\n",
    "$\\newcommand{\\bX}{\\mathbf{X}}$\n",
    "$\\newcommand{\\bT}{\\mathbf{T}}$\n",
    "$\\newcommand{\\bPhi}{\\mathbf{\\Phi}}$\n",
    "$\\newcommand{\\bW}{\\mathbf{W}}$\n",
    "$\\newcommand{\\bV}{\\mathbf{V}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "694e16c6fa7261b60747c28904049744",
     "grade": false,
     "grade_id": "cell-422dbc02437671ac",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "plt.rcParams[\"figure.figsize\"] = [9,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "17f77a32492fcf6ac989eab8a50e4dab",
     "grade": false,
     "grade_id": "cell-821f67d8cd14e4f7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 1. Multiclass logistic regression\n",
    "\n",
    "Scenario: you have a friend with one big problem: she's completely blind. You decided to help her: she has a special smartphone for blind people, and you are going to develop a mobile phone app that can do _machine vision_ using the mobile camera: converting a picture (from the camera) to the meaning of the image. You decide to start with an app that can read handwritten digits, i.e. convert an image of handwritten digits to text (e.g. it would enable her to read precious handwritten phone numbers).\n",
    "\n",
    "A key building block for such an app would be a function `predict_digit(x)` that returns the digit class of an image patch $\\bx$. Since hand-coding this function is highly non-trivial, you decide to solve this problem using machine learning, such that the internal parameters of this function are automatically learned using machine learning techniques.\n",
    "\n",
    "The dataset you're going to use for this is the MNIST handwritten digits dataset (`http://yann.lecun.com/exdb/mnist/`). You can download the data with scikit learn, and load it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b82a7c9aec1e9157526d4fbe12f1d75d",
     "grade": false,
     "grade_id": "cell-bcdbc957165abae7",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "# Fetch the data\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "data, target = mnist.data, mnist.target.astype('int')\n",
    "# Shuffle\n",
    "indices = np.arange(len(data))\n",
    "np.random.seed(123)\n",
    "np.random.shuffle(indices)\n",
    "data, target = data[indices].astype('float32'), target[indices]\n",
    "\n",
    "# Normalize the data between 0.0 and 1.0:\n",
    "data /= 255. \n",
    "\n",
    "# Split\n",
    "x_train, x_valid, x_test = data[:50000], data[50000:60000], data[60000: 70000]\n",
    "t_train, t_valid, t_test = target[:50000], target[50000:60000], target[60000: 70000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5b20138af0810741223d2c2ddc82bf0f",
     "grade": false,
     "grade_id": "cell-b7b4a5a96dccf229",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "MNIST consists of small 28 by 28 pixel images of written digits (0-9). We split the dataset into a training, validation and testing arrays. The variables `x_train`, `x_valid` and `x_test` are $N \\times M$ matrices, where $N$ is the number of datapoints in the respective set, and $M = 28^2 = 784$ is the dimensionality of the data. The second set of variables `t_train`, `t_valid` and `t_test` contain the corresponding $N$-dimensional vector of integers, containing the true class labels.\n",
    "\n",
    "Here's a visualisation of the first 8 digits of the trainingset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "40e1628ec56b6d664edf9aaf496ea637",
     "grade": false,
     "grade_id": "cell-48a92c0a2a2bf4dd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoEAAAFgCAYAAADEo6MCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERRYhNIBEREVGE2AQSERERRej/A71lBRRy4hipAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xacb1fdcc>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_digits(data, num_cols, targets=None, shape=(28,28)):\n",
    "    num_digits = data.shape[0]\n",
    "    num_rows = int(num_digits/num_cols)\n",
    "    for i in range(num_digits):\n",
    "        plt.subplot(num_rows, num_cols, i+1)\n",
    "        plt.imshow(data[i].reshape(shape), interpolation='none', cmap='Greys')\n",
    "        if targets is not None:\n",
    "            plt.title(int(targets[i]))\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_digits(x_train[0:40000:5000], num_cols=4, targets=t_train[0:40000:5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9908b1f7669980cd126946bf7983c096",
     "grade": false,
     "grade_id": "cell-3eb664a58e03bf42",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "In _multiclass_ logistic regression, the conditional probability of class label $j$ given the image $\\bx$ for some datapoint is given by:\n",
    "\n",
    "$ \\log p(t = j \\;|\\; \\bx, \\bb, \\bW) = \\log q_j - \\log Z$\n",
    "\n",
    "where $\\log q_j = \\bw_j^T \\bx + b_j$ (the log of the unnormalized probability of the class $j$), and $Z = \\sum_k q_k$ is the normalizing factor. $\\bw_j$ is the $j$-th column of $\\bW$ (a matrix of size $784 \\times 10$) corresponding to the class label, $b_j$ is the $j$-th element of $\\bb$.\n",
    "\n",
    "Given an input image, the multiclass logistic regression model first computes the intermediate vector $\\log \\bq$ (of size $10 \\times 1$), using $\\log q_j = \\bw_j^T \\bx + b_j$, containing the unnormalized log-probabilities per class. \n",
    "\n",
    "The unnormalized probabilities are then normalized by $Z$ such that $\\sum_j p_j = \\sum_j \\exp(\\log p_j) = 1$. This is done by $\\log p_j = \\log q_j - \\log Z$ where $Z = \\sum_i \\exp(\\log q_i)$. This is known as the _softmax_ transformation, and is also used as a last layer of many classifcation neural network models, to ensure that the output of the network is a normalized distribution, regardless of the values of second-to-last layer ($\\log \\bq$)\n",
    "\n",
    "**Warning**: when computing $\\log Z$, you are likely to encounter numerical problems. Save yourself countless hours of debugging and learn the [log-sum-exp trick](https://hips.seas.harvard.edu/blog/2013/01/09/computing-log-sum-exp/ \"Title\").\n",
    "\n",
    "The network's output $\\log \\bp$ of size $10 \\times 1$ then contains the conditional log-probabilities $\\log p(t = j \\;|\\; \\bx, \\bb, \\bW)$ for each digit class $j$. In summary, the computations are done in this order:\n",
    "\n",
    "$\\bx \\rightarrow \\log \\bq \\rightarrow Z \\rightarrow \\log \\bp$\n",
    "\n",
    "Given some dataset with $N$ independent, identically distributed datapoints, the log-likelihood is given by:\n",
    "\n",
    "$ \\mathcal{L}(\\bb, \\bW) = \\sum_{n=1}^N \\mathcal{L}^{(n)}$\n",
    "\n",
    "where we use $\\mathcal{L}^{(n)}$ to denote the partial log-likelihood evaluated over a single datapoint. It is important to see that the log-probability of the class label $t^{(n)}$ given the image, is given by the $t^{(n)}$-th element of the network's output $\\log \\bp$, denoted by $\\log p_{t^{(n)}}$:\n",
    "\n",
    "$\\mathcal{L}^{(n)} = \\log p(t = t^{(n)} \\;|\\; \\bx = \\bx^{(n)}, \\bb, \\bW) = \\log p_{t^{(n)}} = \\log q_{t^{(n)}} - \\log Z^{(n)}$\n",
    "\n",
    "where $\\bx^{(n)}$ and $t^{(n)}$ are the input (image) and class label (integer) of the $n$-th datapoint, and $Z^{(n)}$ is the normalizing constant for the distribution over $t^{(n)}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dfb50b2b2d11a7b8d1fe9bf5e9586442",
     "grade": false,
     "grade_id": "cell-17766ee789f11384",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1.1 Gradient-based stochastic optimization\n",
    "### 1.1.1 Derive gradient equations (20 points)\n",
    "\n",
    "Derive the equations for computing the (first) partial derivatives of the log-likelihood w.r.t. all the parameters, evaluated at a _single_ datapoint $n$.\n",
    "\n",
    "You should start deriving the equations for $\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log q_j}$ for each $j$. For clarity, we'll use the shorthand $\\delta^q_j = \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log q_j}$.\n",
    "\n",
    "For $j = t^{(n)}$:\n",
    "$\n",
    "\\delta^q_j\n",
    "= \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log p_j}\n",
    "\\frac{\\partial \\log p_j}{\\partial \\log q_j}\n",
    "+ \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log Z}\n",
    "\\frac{\\partial \\log Z}{\\partial Z} \n",
    "\\frac{\\partial Z}{\\partial \\log q_j} \n",
    "= 1 \\cdot 1 - \\frac{\\partial \\log Z}{\\partial Z} \n",
    "\\frac{\\partial Z}{\\partial \\log q_j}\n",
    "= 1 - \\frac{\\partial \\log Z}{\\partial Z} \n",
    "\\frac{\\partial Z}{\\partial \\log q_j}\n",
    "$\n",
    "\n",
    "For $j \\neq t^{(n)}$:\n",
    "$\n",
    "\\delta^q_j\n",
    "= \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log Z}\n",
    "\\frac{\\partial \\log Z}{\\partial Z} \n",
    "\\frac{\\partial Z}{\\partial \\log q_j} \n",
    "= - \\frac{\\partial \\log Z}{\\partial Z} \n",
    "\\frac{\\partial Z}{\\partial \\log q_j}\n",
    "$\n",
    "\n",
    "Complete the above derivations for $\\delta^q_j$ by furtherly developing $\\frac{\\partial \\log Z}{\\partial Z}$ and $\\frac{\\partial Z}{\\partial \\log q_j}$. Both are quite simple. For these it doesn't matter whether $j = t^{(n)}$ or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f394ea0423ed2b17c80bbe8f1193cc81",
     "grade": true,
     "grade_id": "cell-e40110444a1e1d3f",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "For $j = t^{(n)}$:\n",
    "\\begin{align}\n",
    "\\delta^q_j\n",
    "&= 1 - \\frac{\\partial \\log Z}{\\partial Z} \n",
    "\\frac{\\partial Z}{\\partial \\log q_j}\\\\\n",
    "&= 1-\\frac{\\partial \\log Z}{\\partial Z}\\frac{\\partial \\sum_{i}exp(log(q_{i}))}{\\partial log(q_{j})}\\\\\n",
    "&= 1-\\frac{1}{Z}exp(log(q_{j}))\\\\\n",
    "\\delta^q_j &= 1-\\frac{1}{Z}exp(w_{j}^{T}x+b_{j})\n",
    "\\end{align}\n",
    "For $j \\neq t^{(n)}$:\n",
    "\\begin{align}\n",
    "\\delta^q_j\n",
    "&= - \\frac{\\partial \\log Z}{\\partial Z} \n",
    "\\frac{\\partial Z}{\\partial \\log q_j}\\\\\n",
    "&= -\\frac{\\partial \\log Z}{\\partial Z}\\frac{\\partial \\sum_{i}exp(log(q_{i}))}{\\partial log(q_{j})}\\\\\n",
    "&= -\\frac{1}{Z}exp(log(q_{j}))\\\\\n",
    "\\delta^q_j &= -\\frac{1}{Z}exp(w_{j}^{T}x+b_{j})\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d46c028e9830445397d7b2275815990d",
     "grade": false,
     "grade_id": "cell-c770cfe1389ca4ff",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Given your equations for computing the gradients $\\delta^q_j$ it should be quite straightforward to derive the equations for the gradients of the parameters of the model, $\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial W_{ij}}$ and $\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial b_j}$. The gradients for the biases $\\bb$ are given by:\n",
    "\n",
    "$\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial b_j}\n",
    "= \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log q_j}\n",
    "\\frac{\\partial \\log q_j}{\\partial b_j}\n",
    "= \\delta^q_j\n",
    "\\cdot 1\n",
    "= \\delta^q_j\n",
    "$\n",
    "\n",
    "The equation above gives the derivative of $\\mathcal{L}^{(n)}$ w.r.t. a single element of $\\bb$, so the vector $\\nabla_\\bb \\mathcal{L}^{(n)}$ with all derivatives of $\\mathcal{L}^{(n)}$ w.r.t. the bias parameters $\\bb$ is: \n",
    "\n",
    "$\n",
    "\\nabla_\\bb \\mathcal{L}^{(n)} = \\mathbf{\\delta}^q\n",
    "$\n",
    "\n",
    "where $\\mathbf{\\delta}^q$ denotes the vector of size $10 \\times 1$ with elements $\\mathbf{\\delta}_j^q$.\n",
    "\n",
    "The (not fully developed) equation for computing the derivative of $\\mathcal{L}^{(n)}$ w.r.t. a single element $W_{ij}$ of $\\bW$ is:\n",
    "\n",
    "$\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial W_{ij}} =\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log q_j}\n",
    "\\frac{\\partial \\log q_j}{\\partial W_{ij}}\n",
    "= \\mathbf{\\delta}_j^q\n",
    "\\frac{\\partial \\log q_j}{\\partial W_{ij}}\n",
    "$\n",
    "\n",
    "What is $\\frac{\\partial \\log q_j}{\\partial W_{ij}}$? Complete the equation above.\n",
    "\n",
    "If you want, you can give the resulting equation in vector format ($\\nabla_{\\bw_j} \\mathcal{L}^{(n)} = ...$), like we did for $\\nabla_\\bb \\mathcal{L}^{(n)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "70fc98e5b227736e2bb92964a3c7174d",
     "grade": true,
     "grade_id": "cell-e40110444a1asdfasdfd3f",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "\\begin{equation}\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial W_{ij}} =\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log q_j}\n",
    "\\frac{\\partial \\log q_j}{\\partial W_{ij}}\n",
    "= \\mathbf{\\delta}_j^q\n",
    "\\frac{\\partial \\log q_j}{\\partial W_{ij}}\\\\\n",
    "\\end{equation}\n",
    "\n",
    "We can write $\\frac{\\partial \\log q_j}{\\partial W_{ij}}$ as :\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\log q_j}{\\partial W_{ij}}=\\frac{\\partial (\\textbf{w}_{j}^T\\textbf{x} + b_{j})}{\\partial W_{ij}}\n",
    "\\end{equation}\n",
    "\n",
    "Here $\\textbf{x}$ is a column vector of size(M,1) (M is the feature dimension), $\\textbf{w}_j$ is the j$^{th}$ column vector of $\\textbf{W}$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\textbf{w}_{j}^T\\textbf{x} + b_{j}= \\sum_{i=1}^{M}w_{ij}x_{i} +b_{j}\\\\\n",
    "\\frac{\\partial (\\textbf{w}_{j}^T\\textbf{x} + b_{j})}{\\partial W_{ij}}=\\frac{\\partial (\\sum_{i=1}^{M}w_{ij}x_{i} +b_{j})}{{\\partial W_{ij}}}\\\\\n",
    "\\frac{\\partial (\\textbf{w}_{j}^T\\textbf{x} + b_{j})}{\\partial W_{ij}}=x_{i}\n",
    "\\end{equation}\n",
    "\n",
    "We can write $\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial W_{ij}}$ as:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial W_{ij}}=\\mathbf{\\delta}_j^q x_{i}\n",
    "\\end{equation}\n",
    "$\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\textbf{w}_{j}} = \\bigg(\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{1j}},\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{2j}}  ,......, \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{Mj}}\\bigg)\\\\\n",
    "$\n",
    "\\begin{equation}\n",
    "\\nabla_{\\bw_{j}} \\mathcal{L}^{(n)}=\\bigg(\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{1j}},\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{2j}}  ,......, \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{Mj}}\\bigg)^T\\\\\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "99387b4094640d8cd71bfd15687abc31",
     "grade": false,
     "grade_id": "cell-b0f28b0924b9983d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.1.2 Implement gradient computations (10 points)\n",
    "\n",
    "Implement the gradient calculations you derived in the previous question. Write a function `logreg_gradient(x, t, w, b)` that returns the gradients $\\nabla_{\\bw_j} \\mathcal{L}^{(n)}$ (for each $j$) and $\\nabla_{\\bb} \\mathcal{L}^{(n)}$, i.e. the first partial derivatives of the log-likelihood w.r.t. the parameters $\\bW$ and $\\bb$, evaluated at a single datapoint (`x`, `t`).\n",
    "The computation will contain roughly the following intermediate variables:\n",
    "\n",
    "$\n",
    "\\log \\bq \\rightarrow Z \\rightarrow \\log \\bp\\,,\\, \\mathbf{\\delta}^q\n",
    "$\n",
    "\n",
    "followed by computation of the gradient vectors $\\nabla_{\\bw_j} \\mathcal{L}^{(n)}$ (contained in a $784 \\times 10$ matrix) and $\\nabla_{\\bb} \\mathcal{L}^{(n)}$ (a $10 \\times 1$ vector).\n",
    "\n",
    "For maximum points, ensure the function is numerically stable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "46b3dd32a8837896ac75063695c150f8",
     "grade": false,
     "grade_id": "cell-6858f885be587480",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1.1.2 Compute gradient of log p(t|x;w,b) wrt w and b\n",
    "def logsmexp(ns):#calculate log-sum-exponential\n",
    "    max_ = np.max(ns)\n",
    "    ds = ns-max_\n",
    "    sumOfexp = np.exp(ds).sum()\n",
    "#     print(max_+np.log(sumOfexp))\n",
    "    return max_+np.log(sumOfexp)\n",
    "\n",
    "def cal_delta(logq,t,logZ):\n",
    "    delta = -exp(logq)/exp(logZ)\n",
    "    delta[t[0]] +=1\n",
    "        \n",
    "    return delta\n",
    "\n",
    "def cal_dw(x,delta):\n",
    "    dw=(np.tile(x,(10,1))).T\n",
    "    return dw*(delta.T)\n",
    "\n",
    "def logreg_gradient(x, t, w, b):\n",
    "\n",
    "    #Try to maintain matrix dimesnion.Because python can be shit in such cases!! sometimes\n",
    "    b = np.reshape(b,(10,1))\n",
    "    logq= np.dot(x,w).T + b\n",
    "    logZ=logsmexp(logq)\n",
    "    #logp = lopq - logZ. Calculate it for each class. So this will be a vector of (10,1)\n",
    "    #here has been calculated for every j==tn \n",
    "    logp = logq-logZ\n",
    "    #take transpose of logp now size (1,10).transpose is taken just to take care of logp[:,t]\n",
    "    logp = np.transpose(logp)\n",
    "    \n",
    "\n",
    "    #Calculate delta use j=tn and j!=tn to get the delta vector\n",
    "    delta = cal_delta(logq,t,logZ)\n",
    "    dL_db = delta\n",
    "    dL_dw = cal_dw(x,delta)\n",
    "    \n",
    "    return logp[:,t].squeeze(), dL_dw, dL_db.squeeze()\n",
    "\n",
    "\n",
    "# np.random.seed(123)\n",
    "# # scalar, 10 X 768  matrix, 10 X 1 vector\n",
    "# w = np.random.normal(size=(28*28,10), scale=0.001)\n",
    "# # w = np.zeros((784,10))\n",
    "# b = np.zeros((10,1))\n",
    "\n",
    "# # test gradients, train on 1 sample\n",
    "# logpt, grad_w, grad_b = logreg_gradient(x_train[0:1,:], t_train[0:1], w, b)\n",
    "# print(logpt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bcebc974c2a0ac928c9f0381e7e86eec",
     "grade": true,
     "grade_id": "cell-1c9659f607b151a2",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test gradient on one point\n",
      "Likelihood:\t -2.2959726720744777\n",
      "\n",
      "Grad_W_ij\t (784, 10) matrix\n",
      "Grad_W_ij[0,152:158]=\t [-0.04518971 -0.06758809 -0.07819784 -0.09077237 -0.07584012 -0.06365855]\n",
      "\n",
      "Grad_B_i shape\t (10,) vector\n",
      "Grad_B_i=\t [-0.10020327 -0.09977827 -0.1003198   0.89933657 -0.10037941 -0.10072863\n",
      " -0.09982729 -0.09928672 -0.09949324 -0.09931994]\n",
      "i in {0,...,9}; j in M\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "# scalar, 10 X 768  matrix, 10 X 1 vector\n",
    "w = np.random.normal(size=(28*28,10), scale=0.001)\n",
    "# w = np.zeros((784,10))\n",
    "b = np.zeros((10,))\n",
    "\n",
    "# test gradients, train on 1 sample\n",
    "logpt, grad_w, grad_b = logreg_gradient(x_train[0:1,:], t_train[0:1], w, b)\n",
    "\n",
    "print(\"Test gradient on one point\")\n",
    "print(\"Likelihood:\\t\", logpt)\n",
    "print(\"\\nGrad_W_ij\\t\",grad_w.shape,\"matrix\")\n",
    "print(\"Grad_W_ij[0,152:158]=\\t\", grad_w[152:158,0])\n",
    "print(\"\\nGrad_B_i shape\\t\",grad_b.shape,\"vector\")\n",
    "print(\"Grad_B_i=\\t\", grad_b.T)\n",
    "print(\"i in {0,...,9}; j in M\")\n",
    "\n",
    "assert logpt.shape == (), logpt.shape\n",
    "assert grad_w.shape == (784, 10), grad_w.shape\n",
    "assert grad_b.shape == (10,), grad_b.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "72121207fa6163adf16cb3381ddde510",
     "grade": true,
     "grade_id": "cell-fd59c3a03a87ab83",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finite difference error grad_w: 7.50209703432e-07\n",
      "Finite difference error grad_b: 6.58585317291e-08\n"
     ]
    }
   ],
   "source": [
    "# It's always good to check your gradient implementations with finite difference checking:\n",
    "# Scipy provides the check_grad function, which requires flat input variables.\n",
    "# So we write two helper functions that provide can compute the gradient and output with 'flat' weights:\n",
    "from scipy.optimize import check_grad\n",
    "\n",
    "np.random.seed(123)\n",
    "# scalar, 10 X 768  matrix, 10 X 1 vector\n",
    "w = np.random.normal(size=(28*28,10), scale=0.001)\n",
    "# w = np.zeros((784,10))\n",
    "b = np.zeros((10,))\n",
    "\n",
    "def func(w):\n",
    "    logpt, grad_w, grad_b = logreg_gradient(x_train[0:1,:], t_train[0:1], w.reshape(784,10), b)\n",
    "    return logpt\n",
    "def grad(w):\n",
    "    logpt, grad_w, grad_b = logreg_gradient(x_train[0:1,:], t_train[0:1], w.reshape(784,10), b)\n",
    "    return grad_w.flatten()\n",
    "finite_diff_error = check_grad(func, grad, w.flatten())\n",
    "print('Finite difference error grad_w:', finite_diff_error)\n",
    "assert finite_diff_error < 1e-3, 'Your gradient computation for w seems off'\n",
    "\n",
    "def func(b):\n",
    "    logpt, grad_w, grad_b = logreg_gradient(x_train[0:1,:], t_train[0:1], w, b)\n",
    "    return logpt\n",
    "def grad(b):\n",
    "    logpt, grad_w, grad_b = logreg_gradient(x_train[0:1,:], t_train[0:1], w, b)\n",
    "    return grad_b.flatten()\n",
    "finite_diff_error = check_grad(func, grad, b)\n",
    "print('Finite difference error grad_b:', finite_diff_error)\n",
    "assert finite_diff_error < 1e-3, 'Your gradient computation for b seems off'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "82f98bef86ddcf7387f50651a739b189",
     "grade": true,
     "grade_id": "cell-91b8c5eb86f6a0f3",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1aedefd481635db2e213dacbca5959d4",
     "grade": false,
     "grade_id": "cell-bdce061b39aaacec",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "\n",
    "### 1.1.3 Stochastic gradient descent (10 points)\n",
    "\n",
    "Write a function `sgd_iter(x_train, t_train, w, b)` that performs one iteration of stochastic gradient descent (SGD), and returns the new weights. It should go through the trainingset once in randomized order, call `logreg_gradient(x, t, w, b)` for each datapoint to get the gradients, and update the parameters **using a small learning rate of `1E-6`**. Note that in this case we're maximizing the likelihood function, so we should actually performing gradient ___ascent___... For more information about SGD, see Bishop 5.2.4 or an online source (i.e. https://en.wikipedia.org/wiki/Stochastic_gradient_descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a1fd10093bd350a24e4a718bc0133738",
     "grade": true,
     "grade_id": "cell-86bf84658f1c5bc8",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def lgsum(ns): #here ns is some mxn matrix\n",
    "    max_ = np.max(ns,axis=0,keepdims=True)\n",
    "    ds = ns-max_\n",
    "    allexp = np.exp(ds)\n",
    "    smexp =np.sum(allexp,axis=0,keepdims=True)\n",
    "    return max_+np.log(smexp)\n",
    "\n",
    "def log_probability(x_train,t_train,l_w,l_b):\n",
    "    l_b=np.reshape(l_b,(10,1))\n",
    "    logq = np.dot(x_train,l_w).T+l_b\n",
    "    logZ = lgsum(logq)\n",
    "    lgp= logq-logZ\n",
    "#     print(lgp.shape)\n",
    "#     print(lgp,t_train)\n",
    "    c_lgp=[lgp[t_train[i]][i] for i in range(0,len(t_train))]\n",
    "    c_sm = np.sum(np.array(c_lgp))\n",
    "    logp_train=c_sm/len(t_train)\n",
    "#     print(logp_train)\n",
    "    return logp_train\n",
    "\n",
    "\n",
    "def sgd_iter(x_train, t_train, w, b):\n",
    "\n",
    "    learning_rate=10**(-4)\n",
    "    cost=0\n",
    "    for i in range(0,len(t_train)):\n",
    "\n",
    "        logpt, grad_w, grad_b = logreg_gradient(x_train[i:i+1,:], t_train[i:i+1], w, b)\n",
    "#         print(\"jdsdkj\",logpt)\n",
    "        w = w + learning_rate*grad_w\n",
    "        b = b + learning_rate*grad_b\n",
    "        \n",
    "    logp_train=log_probability(x_train, t_train, w, b)    \n",
    "\n",
    "    return logp_train, w, b\n",
    "\n",
    "np.random.seed(1243)\n",
    "w = np.zeros((28*28, 10))\n",
    "b = np.zeros(10)\n",
    "    \n",
    "logp_train, W, b = sgd_iter(x_train[:2], t_train[:2], w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f4eb4ba6aee968be7e896cb4ef74e745",
     "grade": true,
     "grade_id": "cell-2f7bbc264cc887a0",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Sanity check:\n",
    "np.random.seed(1243)\n",
    "w = np.zeros((28*28, 10))\n",
    "b = np.zeros(10)\n",
    "    \n",
    "logp_train, W, b = sgd_iter(x_train[:5], t_train[:5], w, b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "32ce2e1e1bc8ee7c2ed647ea65c6f943",
     "grade": false,
     "grade_id": "cell-81634c804e1f93fc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 1.2. Train\n",
    "\n",
    "### 1.2.1 Train (10 points)\n",
    "Perform 10 SGD iterations through the trainingset. Plot (in one graph) the conditional log-probability of the trainingset and validation set after each iteration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "02d6fffcf7065691be87ea236459d3e1",
     "grade": true,
     "grade_id": "cell-20a347ba4db6e82c",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "<zip object at 0xa745ce4c>\n"
     ]
    }
   ],
   "source": [
    "#Have added one more term in return statement\n",
    "def test_sgd(x_train, t_train, w, b):\n",
    "    \n",
    "    log_probability_train=[]\n",
    "    log_probability_validate=[]\n",
    "    for i in range(0,10):\n",
    "        print(i)\n",
    "        logp_train, w, b =  sgd_iter(x_train, t_train, w, b)\n",
    "        logp_validate = log_probability(x_valid,t_valid,w,b)\n",
    "\n",
    "        log_probability_train.append(logp_train)\n",
    "        log_probability_validate.append(logp_validate)\n",
    "    loggp_train_val = zip(log_probability_train,log_probability_validate)\n",
    "    return loggp_train_val,w,b\n",
    "\n",
    "\n",
    "np.random.seed(1243)\n",
    "w = np.zeros((28*28, 10))\n",
    "b = np.zeros(10)\n",
    "cost, w,b = test_sgd(x_train, t_train, w, b)\n",
    "print(cost)\n",
    "# validate_(x_valid[:5],t_valid[:5],w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAFUCAYAAADCnP1JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nx8zMzMra/wNQrVoIt4A/NgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa6ebe92c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "log_train, log_validate =  zip(*cost)\n",
    "plt.plot(range(0,10),log_train,'ro-')\n",
    "plt.plot(range(0,10),log_validate,'bo-')\n",
    "blue = mpatches.Patch(color='blue', label='log_prob_valid')\n",
    "red = mpatches.Patch(color='red', label='log_prob_train')\n",
    "\n",
    "plt.legend(handles=[blue,red],fontsize=15)\n",
    "plt.ylabel('log_prob',fontsize=15)\n",
    "plt.xlabel(\"Number of iterations\",fontsize=15)\n",
    "plt.title(\"log-likelihood, learning rate 10e(-4) \",fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a6d85bbd97cad35d524b65b23f64e75f",
     "grade": false,
     "grade_id": "cell-cf7f3da57d19493a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.2.2 Visualize weights (10 points)\n",
    "Visualize the resulting parameters $\\bW$ after a few iterations through the training set, by treating each column of $\\bW$ as an image. If you want, you can use or edit the `plot_digits(...)` above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4e554436500eebe1527a31039570a264",
     "grade": true,
     "grade_id": "cell-b10656f35fac065e",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoUAAAFgCAYAAADNSAN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nACIpBAAAgKR/AbfMuwziKRcsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa6fa152c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_digits(data, num_cols, targets=None, shape=(28,28)):\n",
    "    data = np.transpose(data)\n",
    "    print(data.shape)\n",
    "    num_digits = data.shape[0]\n",
    "    num_rows = int(num_digits/num_cols)\n",
    "    for i in range(num_digits):\n",
    "        plt.subplot(num_rows, num_cols, i+1)\n",
    "        plt.imshow(data[i].reshape(shape), interpolation='none', cmap='Greys')\n",
    "        if targets is not None:\n",
    "            plt.title(int(targets[i]))\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#plot_digits1(x_train[0:40000:5000], num_cols=4, targets=t_train[0:40000:5000])\n",
    "plot_digits(w, num_cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "de187afcf5ae1e34b80bc10610760e7a",
     "grade": true,
     "grade_id": "cell-eb131c8b7303da38",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**Describe in less than 100 words why these weights minimize the loss**\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2bb485340ba8ee90a0d8cbc90fc7a7af",
     "grade": false,
     "grade_id": "cell-f36d974d9ef34c97",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.2.3. Visualize the 8 hardest and 8 easiest digits (10 points)\n",
    "Visualize the 8 digits in the validation set with the highest probability of the true class label under the model.\n",
    "Also plot the 8 digits that were assigned the lowest probability.\n",
    "Ask yourself if these results make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7fe3011f6f3ef6f6b00f58bb5dea7b76",
     "grade": true,
     "grade_id": "cell-3802d61680deeff5",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8d3b971f8daced95f5020cfffcb89d02",
     "grade": false,
     "grade_id": "cell-2c525344c99e5b26",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Part 2. Multilayer perceptron\n",
    "\n",
    "\n",
    "You discover that the predictions by the logistic regression classifier are not good enough for your application: the model is too simple. You want to increase the accuracy of your predictions by using a better model. For this purpose, you're going to use a multilayer perceptron (MLP), a simple kind of neural network. The perceptron wil have a single hidden layer $\\bh$ with $L$ elements. The parameters of the model are $\\bV$ (connections between input $\\bx$ and hidden layer $\\bh$), $\\ba$ (the biases/intercepts of $\\bh$), $\\bW$ (connections between $\\bh$ and $\\log q$) and $\\bb$ (the biases/intercepts of $\\log q$.\n",
    "\n",
    "The conditional probability of the class label $j$ is given by:\n",
    "\n",
    "$\\log p(t = j \\;|\\; \\bx, \\bb, \\bW) = \\log q_j - \\log Z$\n",
    "\n",
    "where $q_j$ are again the unnormalized probabilities per class, and $Z = \\sum_j q_j$ is again the probability normalizing factor. Each $q_j$ is computed using:\n",
    "\n",
    "$\\log q_j = \\bw_j^T \\bh + b_j$\n",
    "\n",
    "where $\\bh$ is a $L \\times 1$ vector with the hidden layer activations (of a hidden layer with size $L$), and $\\bw_j$ is the $j$-th column of $\\bW$ (a $L \\times 10$ matrix). Each element of the hidden layer is computed from the input vector $\\bx$ using:\n",
    "\n",
    "$h_j = \\sigma(\\bv_j^T \\bx + a_j)$\n",
    "\n",
    "where $\\bv_j$ is the $j$-th column of $\\bV$ (a $784 \\times L$ matrix), $a_j$ is the $j$-th element of $\\ba$, and $\\sigma(.)$ is the so-called sigmoid activation function, defined by:\n",
    "\n",
    "$\\sigma(x) = \\frac{1}{1 + \\exp(-x)}$\n",
    "\n",
    "Note that this model is almost equal to the multiclass logistic regression model, but with an extra 'hidden layer' $\\bh$. The activations of this hidden layer can be viewed as features computed from the input, where the feature transformation ($\\bV$ and $\\ba$) is learned.\n",
    "\n",
    "## 2.1 Derive gradient equations (20 points)\n",
    "\n",
    "State (shortly) why $\\nabla_{\\bb} \\mathcal{L}^{(n)}$ is equal to the earlier (multiclass logistic regression) case, and why $\\nabla_{\\bw_j} \\mathcal{L}^{(n)}$ is almost equal to the earlier case.\n",
    "\n",
    "Like in multiclass logistic regression, you should use intermediate variables $\\mathbf{\\delta}_j^q$. In addition, you should use intermediate variables $\\mathbf{\\delta}_j^h = \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial h_j}$.\n",
    "\n",
    "Given an input image, roughly the following intermediate variables should be computed:\n",
    "\n",
    "$\n",
    "\\log \\bq \\rightarrow Z \\rightarrow \\log \\bp \\rightarrow \\mathbf{\\delta}^q \\rightarrow \\mathbf{\\delta}^h\n",
    "$\n",
    "\n",
    "where $\\mathbf{\\delta}_j^h = \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\bh_j}$.\n",
    "\n",
    "Give the equations for computing $\\mathbf{\\delta}^h$, and for computing the derivatives of $\\mathcal{L}^{(n)}$ w.r.t. $\\bW$, $\\bb$, $\\bV$ and $\\ba$. \n",
    "\n",
    "You can use the convenient fact that $\\frac{\\partial}{\\partial x} \\sigma(x) = \\sigma(x) (1 - \\sigma(x))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bb7ce29f01484f94a6357784ddaf6412",
     "grade": true,
     "grade_id": "cell-48f48bb8ec75cc3c",
     "locked": false,
     "points": 20,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Let's start with calculating $\\delta^q_j=\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log q_j}$\n",
    "\n",
    "$j = t^{(n)}$\n",
    "\\begin{align}\n",
    "\\delta^q_j &= \\frac{\\partial (\\log q_j -\\log Z)}{\\partial \\log q_j }\\\\\n",
    " &= \\frac{\\partial \\log q_j}{\\partial \\log q_j } -\\frac{\\partial \\log Z}{\\partial Z}\\frac{\\partial Z}{\\log q_j}\\\\\n",
    " &= 1-\\frac{1}{Z}\\frac{\\partial \\sum_{j}\\exp(\\log q_{j})}{\\partial \\log q_{j}}\\\\\n",
    " &= 1-\\frac{1}{Z} \\exp(\\log q_{j})\\\\\n",
    " &= 1-\\frac{1}{Z} \\exp(\\bw_j^T \\bh + b_j)\\\\\n",
    " \\end{align}\n",
    " $j \\neq t^{(n)}$\n",
    " \\begin{align}\n",
    " \\delta^q_j &= -\\frac{1}{Z}\\frac{\\partial \\sum_{j}\\exp(\\log q_{j})}{\\partial \\log q_{j}}\\\\\n",
    " &= -\\frac{1}{Z} \\exp(\\log q_{j})\\\\\n",
    " &= -\\frac{1}{Z} \\exp(\\bw_j^T \\bh + b_j)\\\\\n",
    " \\end{align}\n",
    " \n",
    "$ \n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial b_j}\n",
    "= \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log q_j}\n",
    "\\frac{\\partial \\log q_j}{\\partial b_j}\n",
    "= \\delta^q_j\n",
    "\\cdot 1\n",
    "= \\delta^q_j\\\\\n",
    "\\nabla_\\bb \\mathcal{L}^{(n)} = \\mathbf{\\delta}^q\n",
    "$\n",
    "\n",
    "Calculating $\\frac{\\mathcal{L}^{(n)}}{\\partial \\bw_{ij}}$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial\\bw_{ij}} =\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log q_j}\n",
    "\\frac{\\partial \\log q_j}{\\partial \\bw_{ij}}\n",
    "= \\mathbf{\\delta}_j^q\n",
    "\\frac{\\partial \\log q_j}{\\partial \\bw_{ij}}\\\\\n",
    "\\end{equation}\n",
    "We can write $\\frac{\\partial \\log q_j}{\\partial W_{ij}}$ as :\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\log q_j}{\\partial \\bw_{ij}}=\\frac{\\partial (\\bw_{j}^T \\bh + b_{j})}{\\partial \\bw_{ij}}\n",
    "\\end{equation}\n",
    "Here $\\textbf{h}$ is a column vector of size $(\\textbf{L},1)$ ($\\textbf{L}$ is no. of hidden units), $\\textbf{w}_j$ is the j$^{th}$ column vector of $\\textbf{W}$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\textbf{w}_{j}^T\\textbf{x} + b_{j}= \\sum_{i=1}^{L}w_{ij}h_{i} +b_{j}\\\\\n",
    "\\frac{\\partial (\\textbf{w}_{j}^T\\textbf{h} + b_{j})}{\\partial w_{ij}}=\\frac{\\partial (\\sum_{i=1}^{M}w_{ij}h_{i} +b_{j})}{{\\partial w_{ij}}}\\\\\n",
    "\\frac{\\partial (\\textbf{w}_{j}^T\\textbf{h} + b_{j})}{\\partial w_{ij}}=h_{i}\n",
    "\\end{equation}\n",
    "\n",
    "We can write $\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial W_{ij}}$ as:\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{ij}}=\\mathbf{\\delta}_j^q h_{i}\n",
    "\\end{equation}\n",
    "$\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\textbf{w}_{j}} = \\bigg(\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{1j}},\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{2j}}  ,......, \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{Lj}}\\bigg)\\\\\n",
    "$\n",
    "\\begin{equation}\n",
    "\\nabla_{\\bw_{j}} \\mathcal{L}^{(n)}=\\bigg(\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{1j}},\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{2j}}  ,......, \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial w_{Lj}}\\bigg)^T\\\\\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\nabla_{\\bW} \\mathcal{L}^{(n)}=\\bigg(\\nabla_{\\bw_{1}} \\mathcal{L}^{(n)},......,\\nabla_{\\bw_{10}} \\mathcal{L}^{(n)}\\bigg)\\\\\n",
    "\\end{equation}\n",
    "\n",
    "The above derived equation are just the same as derived in the very first question. But with the minor changes. previously our $\\log q_{j}$ is dependent on our input feature linearly $\\log q_j = \\bw_j^T \\bx + b_j$. But in this case we have a hidden layer. Now our  $\\log q_{j}$ is linearly dependent on the activations from each of the hidden units in the hidden layer $\\log q_j = \\bw_j^T \\bh + b_j$. This what what makes the difference as compared to previous one $\\nabla_\\bb \\mathcal{L}^{(n)}$ and $\\nabla_{\\bW} \\mathcal{L}^{(n)}$.\n",
    "\n",
    "Now Let's calculate  $\\mathbf{\\delta}_j^h = \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\bh_j}$.\n",
    "\n",
    "$\\mathbf{\\delta}_j^h = \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\bh_j}= \\sum_{k}^{10}\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial \\log q_j}\\frac{\\partial log q_k}{\\partial \\bh_{j}}$.\n",
    "\n",
    "Here k varies from 1 to 10.\n",
    "\\begin{align}\n",
    "\\mathbf{\\delta}_j^h &= \\sum_{k} \\mathbf{\\delta}_k^q\\frac{\\partial \\log q_k}{\\partial h_j} \n",
    "= \\sum_{k} \\mathbf{\\delta}_k^q\\frac{\\partial (\\bw_j^T \\bh + b_j) }{\\partial h_j}\\\\\n",
    "&= \\sum_{k} \\mathbf{\\delta}_k^q\\frac{\\partial (\\sum_{i}^{L} w_{ik}h_{i} + b_j) }{\\partial h_j}\\\\\n",
    "\\end{align}\n",
    "\n",
    "at $i=j$\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{\\delta}_j^h &= \\sum_{k} \\mathbf{\\delta}_k^q w_{jk}\\\\\n",
    "\\end{align}\n",
    "\n",
    "Calculate $ \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial a_j}$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial a_j}&=\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial h_j}\\frac{\\partial h_j}{\\partial a_j}\\\\\n",
    "\\end{align}\n",
    "\n",
    "Before moving further Let's calculate $\\frac{\\partial h_j}{\\partial a_j}$ where $h_j = \\sigma(\\bv_j^T \\bx + a_j)$.\\\\\n",
    "\n",
    "$h_j = \\sigma(g_j)$ where $g_j=\\bv_j^T \\bx + a_j$ \n",
    "\n",
    "Now we can write: \n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial h_j}{\\partial a_j}&= \\frac{\\partial h_j}{\\partial g_j}\\frac{\\partial a_j}{\\partial a_j}\\\\\n",
    "&= \\sigma(g_j)(1-\\sigma(g_j))\\cdot 1\\\\\n",
    "\\end{align}\n",
    "Now we can write $\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial a_j}$ as:\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial a_j}&=\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial h_j}\\sigma(g_j)(1-\\sigma(g_j))\\\\\n",
    "&= \\mathbf{\\delta}_j^h  \\sigma(g_j)(1-\\sigma(g_j))\\\\\n",
    "\\end{align}\n",
    " $\\nabla_{\\ba} \\mathcal{L}^{(n)} =\\mathbf{\\delta}^h \\cdot \\sigma(g)(1-\\sigma(g)) $\n",
    " \n",
    " Where dot denotes element wise multiplication.\n",
    " \n",
    " Calculate $\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial v_{ij}}$\n",
    " \\begin{align}\n",
    " \\frac{\\partial \\mathcal{L}^{(n)}}{\\partial v_{ij}}&=\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial h_j}\\frac{\\partial h_j}{\\partial v_{ij}}\\\\\n",
    " &=\\mathbf{\\delta}_j^h  \\sigma(g_j)(1-\\sigma(g_j)\\frac{\\partial g_{j}}{\\partial v_{ij}}\\\\\n",
    " &=\\mathbf{\\delta}_j^h  \\sigma(g_j)(1-\\sigma(g_j)\\frac{\\partial( \\bv_j^T\\bx + a_j)}{\\partial v_{ij}}\\\\\n",
    " &=\\mathbf{\\delta}_j^h  \\sigma(g_j)(1-\\sigma(g_j)\\frac{\\partial \\sum_{i}^{M}v_{ij}x_i + a_j}{\\partial v_{ij}}\\\\\n",
    "  &=\\mathbf{\\delta}_j^h  \\sigma(g_j)(1-\\sigma(g_j)x_{i}\\\\\n",
    " \\end{align}\n",
    " \n",
    " \\begin{align}\n",
    "  \\nabla_{\\bv_j} \\mathcal{L}^{(n)} &=\\bigg(\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial v_{1j}},.......,\\frac{\\partial \\mathcal{L}^{(n)}}{\\partial v_{Mj}} \\bigg)^T\\\\\n",
    "    \\nabla_{\\bV} \\mathcal{L}^{(n)}&=\\bigg(\\nabla_{\\bv_{1}} \\mathcal{L}^{(n)},......,\\nabla_{\\bv_{L}} \\mathcal{L}^{(n)}\\bigg)\\\\\n",
    " \\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cfcfec5959134f7f3fca2ba585a94fba",
     "grade": false,
     "grade_id": "cell-0bff945081e993fc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 2.2 MAP optimization (10 points)\n",
    "\n",
    "You derived equations for finding the _maximum likelihood_ solution of the parameters. Explain, in a few sentences, how you could extend this approach so that it optimizes towards a _maximum a posteriori_ (MAP) solution of the parameters, with a Gaussian prior on the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "49d6376929b1cdf60a9ca9282512f1b4",
     "grade": true,
     "grade_id": "cell-1daef2744c010b73",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "02e47e2058c064a6f9518077e62a9357",
     "grade": false,
     "grade_id": "cell-2e56d8a567e2fb08",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## 2.3. Implement and train a MLP (15 points)\n",
    "\n",
    "Implement a MLP model with a single hidden layer of **20 neurons**. \n",
    "Train the model for **10 epochs**.\n",
    "Plot (in one graph) the conditional log-probability of the trainingset and validation set after each two iterations, as well as the weights.\n",
    "\n",
    "- 10 points: Working MLP that learns with plots\n",
    "- +5 points: Fast, numerically stable, vectorized implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "f8772d3e65d7f1bef5b739a62c2e192f",
     "grade": true,
     "grade_id": "cell-5d1924ace9e216e2",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1.0 + np.exp(-z))\n",
    "\n",
    "def lgsum(ns): #here ns is some mxn matrix\n",
    "    max_ = np.max(ns,axis=0,keepdims=True)\n",
    "    ds = ns-max_\n",
    "    allexp = np.exp(ds)\n",
    "    smexp =np.sum(allexp,axis=0,keepdims=True)\n",
    "    return max_+np.log(smexp)\n",
    "    \n",
    "def tot_log_prob(x,y,parameters):\n",
    "    #run a fwd pass on entire dataset on learned parameters\n",
    "    print(x.shape,y.shape)\n",
    "    V=parameters[\"V\"]\n",
    "    a=parameters[\"a\"]\n",
    "    W=parameters[\"W\"]\n",
    "    b=parameters[\"b\"]\n",
    "#     print(a)\n",
    "#     print(V.shape,a.shape, W.shape, b.shape)\n",
    "    h = sigmoid(np.dot(x,V).T+a)\n",
    "    logq= np.dot(h.T,W).T+b\n",
    "    logZ= lgsum(logq) \n",
    "    logp= logq-logZ\n",
    "#     print(h.shape,logq.shape,logZ.shape,logp.shape)\n",
    "    c_lgp=[logp[y[i]][i] for i in range(0,len(y))]\n",
    "    c_sm = np.sum(np.array(c_lgp))\n",
    "    logp_train=c_sm\n",
    "#     print(logp_train)\n",
    "    return logp_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def layer_sizes(x_train,t_train,L,n_class):\n",
    "    '''\n",
    "    Returns:\n",
    "        n_x -- the size of the input layer\n",
    "        n_h -- the size of the hidden layer\n",
    "        n_y -- the size of the output layer\n",
    "    '''\n",
    "    n_x = x_train.shape[1]\n",
    "    n_h = L\n",
    "    n_y = n_class\n",
    "    \n",
    "    return n_x,n_h,n_y\n",
    "\n",
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    V -- weight matrix of shape (n_x,n_h)\n",
    "                    a -- bias vector of shape (n_h, 1)\n",
    "                    W -- weight matrix of shape (n_h,n_y)\n",
    "                    b -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"  \n",
    "                    \n",
    "    V = np.random.normal(size=(n_x,n_h), scale=0.001)   \n",
    "    a = np.zeros((n_h,1))\n",
    "    W = np.random.normal(size=(n_h,n_y), scale=0.001)\n",
    "    b = np.zeros((n_y,1))  \n",
    "    \n",
    "#     print(V.shape,a.shape,W.shape,b.shape)\n",
    "        \n",
    "    assert V.shape == (n_x,n_h)\n",
    "    assert a.shape == (n_h,1)\n",
    "    assert W.shape == (n_h,n_y)\n",
    "    assert b.shape == (n_y,1)\n",
    "    \n",
    "    parameters = {\"V\": V,\n",
    "                  \"a\": a,\n",
    "                  \"W\": W,\n",
    "                  \"b\": b}\n",
    "    \n",
    "    return parameters\n",
    "\n",
    "def cal_dh(x,delta):\n",
    "    dw=(np.tile(x,(20,1))).T\n",
    "    return dw*(delta.T)\n",
    "#this will calculate gradients of all the parameters\n",
    "\n",
    "def cal_gradient(x_train,t_train,parameters):\n",
    "    #for each training example this will calculate gradients through backpropagation\n",
    "    V=parameters[\"V\"]\n",
    "    a=parameters[\"a\"]\n",
    "    W=parameters[\"W\"]\n",
    "    b=parameters[\"b\"]\n",
    "\n",
    "    ##Forward Prop\n",
    "\n",
    "    h= sigmoid(np.dot(x_train,V).T+a)\n",
    "    logq = np.dot(h.T,W).T + b\n",
    "    logZ = logsmexp(logq)\n",
    "    loqp= logq-logZ\n",
    "    loqp = np.transpose(loqp)\n",
    "\n",
    "    ##forward Props ends\n",
    "    \n",
    "    #Back Propogation\n",
    "    #Calculate delta use j=tn and j!=tn to get the delta vector. These gradients are for ouput layer\n",
    "    deltaq = cal_delta(logq,t_train,logZ)\n",
    "    dL_b = deltaq\n",
    "    dL_w = cal_dw(h.T,deltaq)\n",
    "    #calculate gradient for hidden parameters\n",
    "    deltah = np.dot(W,deltaq)\n",
    "    dL_a = deltah*np.multiply(h,(1-h))\n",
    "    dL_v = cal_dh(x_train,dL_a)\n",
    "\n",
    "    #backprop ends\n",
    "    \n",
    "    assert V.shape == dL_v.shape\n",
    "    assert a.shape == dL_a.shape\n",
    "    assert W.shape == dL_w.shape\n",
    "    assert b.shape == dL_b.pykernel_launcher.py:3: RuntimeWarning: overflow encountered in expshape\n",
    "    grads = {\"dL_v\": dL_v,\n",
    "             \"dL_a\": dL_a,\n",
    "             \"dL_w\": dL_w,\n",
    "             \"dL_b\": dL_b}\n",
    "    return grads\n",
    "\n",
    "def sgd_mlp_iter(x_train, t_train, parameters,learning_rate):\n",
    "\n",
    "    V=parameters[\"V\"]\n",
    "    a=parameters[\"a\"]\n",
    "    W=parameters[\"W\"]\n",
    "    b=parameters[\"b\"]\n",
    "    for i in range(0,len(t_train)):\n",
    "\n",
    "        grad = cal_gradient(x_train[i:i+1,:], t_train[i:i+1],parameters)\n",
    "        grad_w=grad[\"dL_w\"]\n",
    "        grad_b=grad[\"dL_b\"]\n",
    "        grad_v=grad[\"dL_v\"]\n",
    "        grad_a=grad[\"dL_a\"]\n",
    "        \n",
    "#         print(\"jdsdkj\",logpt)\n",
    "        W = W + learning_rate*grad_w\n",
    "        b = b + learning_rate*grad_b\n",
    "        V = V + learning_rate*grad_v\n",
    "        a = a + learning_rate*grad_a\n",
    "    #parameters after one complete training\n",
    "    parameters = {\"V\": V,\n",
    "                  \"a\": a,\n",
    "                  \"W\": W,\n",
    "                  \"b\": b}\n",
    "#     tot_log_prob(x_train,t_train,parameters)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "\n",
    "n_x,n_h,n_y=layer_sizes(x_train,t_train,20,10)\n",
    "parameters=initialize_parameters(n_x, n_h, n_y)\n",
    "\n",
    "grads=cal_gradient(x_train[0:1,:],t_train[0:1],parameters)\n",
    "# parameters=sgd_mlp_iter(x_train, t_train, parameters)\n",
    "# parameters=sgd_mlp_iter(x_train, t_train, parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "301c1950ea79e09141e8ed170bd8b21b",
     "grade": true,
     "grade_id": "cell-e9b2125a5ea8a22c",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(50000, 784) (50000,)\n",
      "(10000, 784) (10000,)\n",
      "1\n",
      "(50000, 784) (50000,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarun/miniconda3/envs/mllab/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000,)\n",
      "2\n",
      "(50000, 784) (50000,)\n",
      "(10000, 784) (10000,)\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tarun/miniconda3/envs/mllab/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in exp\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/tarun/miniconda3/envs/mllab/lib/python3.6/site-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-be707adbaf95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#random shuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgd_mlp_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mlog_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mlog_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-98c296174c2e>\u001b[0m in \u001b[0;36msgd_mlp_iter\u001b[0;34m(x_train, t_train, parameters, learning_rate)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;31m#         print(\"jdsdkj\",logpt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_w\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrad_v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Train and Plots\n",
    "training_epochs=10\n",
    "learning_rate=10**(-1)\n",
    "L=20    #no. of hidden units\n",
    "total_class =10\n",
    "n_x,n_h,n_y= layer_sizes(x_train,t_train,L,total_class)\n",
    "parameters = initialize_parameters(n_x, n_h, n_y) #initalize params\n",
    "\n",
    "log_tr=[]\n",
    "log_val=[]\n",
    "for i in range(0,training_epochs):\n",
    "    #random shuffle\n",
    "    print(i)\n",
    "    parameters = sgd_mlp_iter(x_train, t_train, parameters,learning_rate)\n",
    "    log_tr.append(tot_log_prob(x_train,t_train,parameters))\n",
    "    log_val.append(tot_log_prob(x_valid,t_valid,parameters))\n",
    "\n",
    "plt.plot(range(0,10),log_tr,'ro-')\n",
    "plt.plot(range(0,10),log_val,'bo-')\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_digits(data, num_cols, targets=None, shape=(28,28)):\n",
    "    data = np.transpose(data)\n",
    "    print(data.shape)\n",
    "    num_digits = data.shape[0]\n",
    "    num_rows = int(num_digits/num_cols)\n",
    "    for i in range(num_digits):\n",
    "        plt.subplot(num_rows, num_cols, i+1)\n",
    "        plt.imshow(data[i].reshape(shape), interpolation='none', cmap='Greys')\n",
    "        if targets is not None:\n",
    "            plt.title(int(targets[i]))\n",
    "        plt.colorbar()\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#plot_digits1(x_train[0:40000:5000], num_cols=4, targets=t_train[0:40000:5000])\n",
    "plot_digits(w, num_cols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "555a73588f1a55d1185064f5a6192cac",
     "grade": false,
     "grade_id": "cell-6ae8cb5a4c246b97",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.3.1. Explain the weights (5 points)\n",
    "In less than 80 words, explain how and why the weights of the hidden layer of the MLP differ from the logistic regression model, and relate this to the stronger performance of the MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7f6cbf48a398f8722f4d403b957b2075",
     "grade": true,
     "grade_id": "cell-c4fdc27b1aab6828",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "Weights associated with hidden layers of MLP diifer from"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fa501d2127075b733105148f21adbaf2",
     "grade": false,
     "grade_id": "cell-df7f372be57b921b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.3.1. Less than 250 misclassifications on the test set (10 bonus points)\n",
    "\n",
    "You receive an additional 10 bonus points if you manage to train a model with very high accuracy: at most 2.5% misclasified digits on the test set. Note that the test set contains 10000 digits, so you model should misclassify at most 250 digits. This should be achievable with a MLP model with one hidden layer. See results of various models at : `http://yann.lecun.com/exdb/mnist/index.html`. To reach such a low accuracy, you probably need to have a very high $L$ (many hidden units), probably $L > 200$, and apply a strong Gaussian prior on the weights. In this case you are allowed to use the validation set for training.\n",
    "You are allowed to add additional layers, and use convolutional networks, although that is probably not required to reach 2.5% misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "3d3ce073f1614deb4cc03de3f19879aa",
     "grade": false,
     "grade_id": "cell-2ea313ac02319aa0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "predict_test = np.zeros(len(t_test))\n",
    "# Fill predict_test with the predicted targets from your model, don't cheat :-).\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b540e8fc73d65a4cc4139d9841e4aaba",
     "grade": true,
     "grade_id": "cell-4ad977cd0b7d27df",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert predict_test.shape == t_test.shape\n",
    "n_errors = np.sum(predict_test != t_test)\n",
    "print('Test errors: %d' % n_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
